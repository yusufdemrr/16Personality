{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87011676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624d0e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>You regularly make new friends.</th>\n",
       "      <th>You spend a lot of your free time exploring various random topics that pique your interest</th>\n",
       "      <th>Seeing other people cry can easily make you feel like you want to cry too</th>\n",
       "      <th>You often make a backup plan for a backup plan.</th>\n",
       "      <th>You usually stay calm, even under a lot of pressure</th>\n",
       "      <th>At social events, you rarely try to introduce yourself to new people and mostly talk to the ones you already know</th>\n",
       "      <th>You prefer to completely finish one project before starting another.</th>\n",
       "      <th>You are very sentimental.</th>\n",
       "      <th>You like to use organizing tools like schedules and lists.</th>\n",
       "      <th>Even a small mistake can cause you to doubt your overall abilities and knowledge.</th>\n",
       "      <th>...</th>\n",
       "      <th>You believe that pondering abstract philosophical questions is a waste of time.</th>\n",
       "      <th>You feel more drawn to places with busy, bustling atmospheres than quiet, intimate places.</th>\n",
       "      <th>You know at first glance how someone is feeling.</th>\n",
       "      <th>You often feel overwhelmed.</th>\n",
       "      <th>You complete things methodically without skipping over any steps.</th>\n",
       "      <th>You are very intrigued by things labeled as controversial.</th>\n",
       "      <th>You would pass along a good opportunity if you thought someone else needed it more.</th>\n",
       "      <th>You struggle with deadlines.</th>\n",
       "      <th>You feel confident that things will work out for you.</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>ISFP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>ISTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   You regularly make new friends.  \\\n",
       "0                                0   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                0   \n",
       "4                                0   \n",
       "\n",
       "   You spend a lot of your free time exploring various random topics that pique your interest  \\\n",
       "0                                                  0                                            \n",
       "1                                                  0                                            \n",
       "2                                                  0                                            \n",
       "3                                                 -1                                            \n",
       "4                                                  0                                            \n",
       "\n",
       "   Seeing other people cry can easily make you feel like you want to cry too  \\\n",
       "0                                                  0                           \n",
       "1                                                 -2                           \n",
       "2                                                  2                           \n",
       "3                                                  3                           \n",
       "4                                                 -1                           \n",
       "\n",
       "   You often make a backup plan for a backup plan.  \\\n",
       "0                                                0   \n",
       "1                                               -3   \n",
       "2                                                0   \n",
       "3                                               -1   \n",
       "4                                                0   \n",
       "\n",
       "   You usually stay calm, even under a lot of pressure  \\\n",
       "0                                                  0     \n",
       "1                                                 -1     \n",
       "2                                                 -1     \n",
       "3                                                  0     \n",
       "4                                                  2     \n",
       "\n",
       "   At social events, you rarely try to introduce yourself to new people and mostly talk to the ones you already know  \\\n",
       "0                                                  1                                                                   \n",
       "1                                                  2                                                                   \n",
       "2                                                  2                                                                   \n",
       "3                                                  0                                                                   \n",
       "4                                                 -1                                                                   \n",
       "\n",
       "   You prefer to completely finish one project before starting another.  \\\n",
       "0                                                  1                      \n",
       "1                                                 -2                      \n",
       "2                                                  0                      \n",
       "3                                                 -2                      \n",
       "4                                                 -2                      \n",
       "\n",
       "   You are very sentimental.  \\\n",
       "0                          0   \n",
       "1                          0   \n",
       "2                          0   \n",
       "3                          0   \n",
       "4                          0   \n",
       "\n",
       "   You like to use organizing tools like schedules and lists.  \\\n",
       "0                                                  0            \n",
       "1                                                  3            \n",
       "2                                                  1            \n",
       "3                                                 -2            \n",
       "4                                                  1            \n",
       "\n",
       "   Even a small mistake can cause you to doubt your overall abilities and knowledge.  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "   You believe that pondering abstract philosophical questions is a waste of time.  \\\n",
       "0                                                  0                                 \n",
       "1                                                  0                                 \n",
       "2                                                  0                                 \n",
       "3                                                  0                                 \n",
       "4                                                  0                                 \n",
       "\n",
       "   You feel more drawn to places with busy, bustling atmospheres than quiet, intimate places.  \\\n",
       "0                                                  0                                            \n",
       "1                                                 -2                                            \n",
       "2                                                  2                                            \n",
       "3                                                  0                                            \n",
       "4                                                  1                                            \n",
       "\n",
       "   You know at first glance how someone is feeling.  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                -1   \n",
       "4                                                 0   \n",
       "\n",
       "   You often feel overwhelmed.  \\\n",
       "0                           -1   \n",
       "1                            2   \n",
       "2                            2   \n",
       "3                           -1   \n",
       "4                            2   \n",
       "\n",
       "   You complete things methodically without skipping over any steps.  \\\n",
       "0                                                  0                   \n",
       "1                                                  0                   \n",
       "2                                                 -1                   \n",
       "3                                                  0                   \n",
       "4                                                  0                   \n",
       "\n",
       "   You are very intrigued by things labeled as controversial.  \\\n",
       "0                                                  0            \n",
       "1                                                 -1            \n",
       "2                                                  0            \n",
       "3                                                  1            \n",
       "4                                                  1            \n",
       "\n",
       "   You would pass along a good opportunity if you thought someone else needed it more.  \\\n",
       "0                                                  0                                     \n",
       "1                                                 -1                                     \n",
       "2                                                  1                                     \n",
       "3                                                  0                                     \n",
       "4                                                 -1                                     \n",
       "\n",
       "   You struggle with deadlines.  \\\n",
       "0                             0   \n",
       "1                            -1   \n",
       "2                             2   \n",
       "3                            -2   \n",
       "4                             2   \n",
       "\n",
       "   You feel confident that things will work out for you.  Personality  \n",
       "0                                                  0             ENFP  \n",
       "1                                                  3             ISFP  \n",
       "2                                                  1             INFJ  \n",
       "3                                                 -1             ISTP  \n",
       "4                                                 -1             ENFJ  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file and create a Pandas DataFrame\n",
    "df = pd.read_csv('16P.csv', encoding='cp1252')\n",
    "\n",
    "# Drop the 'Response Id' column from the DataFrame\n",
    "df = df.drop(columns={'Response Id'})\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247fd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to array\n",
    "array = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf47f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 'ENFP'],\n",
       "       [0, 0, -2, ..., -1, 3, 'ISFP'],\n",
       "       [0, 0, 2, ..., 2, 1, 'INFJ'],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, -1, 'ISTP'],\n",
       "       [0, 0, 1, ..., 1, 0, 'ISTJ'],\n",
       "       [0, 0, 2, ..., 0, -1, 'INFJ']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e962a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "278e9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns in the array\n",
    "n = len(array[0])-1\n",
    "\n",
    "# Extract the labels from the array\n",
    "labels = [i[n] for i in array]\n",
    "\n",
    "# Remove the label column from the array\n",
    "array = np.delete(array, n, axis=1)\n",
    "\n",
    "# Convert the labels to a numpy array\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047f7b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, -2, ..., -1, -1, 3],\n",
       "       [0, 0, 2, ..., 1, 2, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., -1, 0, -1],\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 2, ..., 1, 0, -1]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b9a9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENFP', 'ISFP', 'INFJ', ..., 'ISTP', 'ISTJ', 'INFJ'], dtype='<U4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9781c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of personality types\n",
    "personality_types = [\"ESTJ\", \"ENTJ\", \"ESFJ\", \"ENFJ\", \"ISTJ\", \"ISFJ\", \"INTJ\", \"INFJ\", \"ESTP\", \n",
    "                     \"ESFP\", \"ENTP\", \"ENFP\", \"ISTP\", \"ISFP\", \"INTP\", \"INFP\"]\n",
    "\n",
    "\n",
    "# Encode a personality type as an integer\n",
    "def encode_personality_type(personality_type):\n",
    "    return personality_types.index(personality_type)\n",
    "\n",
    "# Decode an encoded personality type as a string\n",
    "def decode_personality_type(index):\n",
    "    return personality_types[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c490dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the given array into 5 folds for cross-validation.\n",
    "def five_fold(array):\n",
    "    global X_trains,X_tests,y_trains,y_tests\n",
    "    \n",
    "    # Size of each fold\n",
    "    size = 12000\n",
    "    \n",
    "    # Split the array into 5 folds\n",
    "    fold1 = array[0:size]                                            \n",
    "    fold2 = array[size:size*2]\n",
    "    fold3 = array[size*2:size*3]\n",
    "    fold4 = array[size*3:size*4]\n",
    "    fold5 = array[size*4:size*5]\n",
    "    \n",
    "    # Split the labels into 5 folds\n",
    "    label1 = labels[0:size]                                            \n",
    "    label2 = labels[size:size*2]\n",
    "    label3 = labels[size*2:size*3]\n",
    "    label4 = labels[size*3:size*4]\n",
    "    label5 = labels[size*4:size*5]\n",
    "    \n",
    "    # Concatenate the folds to create the training sets\n",
    "    X1_train = np.concatenate((fold1,fold2,fold3,fold4))\n",
    "    X2_train = np.concatenate((fold1,fold2,fold3,fold5))\n",
    "    X3_train = np.concatenate((fold1,fold2,fold5,fold4))\n",
    "    X4_train = np.concatenate((fold1,fold5,fold3,fold4))\n",
    "    X5_train = np.concatenate((fold5,fold2,fold3,fold4))\n",
    "    \n",
    "    # Assign each fold to be a test set\n",
    "    X1_test = fold5\n",
    "    X2_test = fold4\n",
    "    X3_test = fold3\n",
    "    X4_test = fold2\n",
    "    X5_test = fold1\n",
    "    \n",
    "    # Concatenate the labels to create the training sets\n",
    "    y1_train = np.concatenate((label1,label2,label3,label4))\n",
    "    y2_train = np.concatenate((label1,label2,label3,label5))\n",
    "    y3_train = np.concatenate((label1,label2,label5,label4))\n",
    "    y4_train = np.concatenate((label1,label5,label3,label4))\n",
    "    y5_train = np.concatenate((label5,label2,label3,label4))\n",
    "    \n",
    "    # Assign each label fold to be a test set\n",
    "    y1_test = label5\n",
    "    y2_test = label4\n",
    "    y3_test = label3\n",
    "    y4_test = label2\n",
    "    y5_test = label1\n",
    "    \n",
    "    # Store the training and test sets for each fold in global variables\n",
    "    X_trains = X1_train, X2_train, X3_train, X4_train, X5_train\n",
    "    X_tests = X1_test, X2_test, X3_test, X4_test, X5_test\n",
    "    y_trains = y1_train, y2_train, y3_train, y4_train, y5_train\n",
    "    y_tests = y1_test, y2_test, y3_test, y4_test, y5_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ded707bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "five_fold(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0af91e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(array):\n",
    "    # Get the number of rows and columns in the array\n",
    "    n = len(array)\n",
    "    m = len(array[0])\n",
    "    \n",
    "    for i in range(m):\n",
    "        # Find the maximum and minimum values in the column\n",
    "        max_val = max(array[j][i] for j in range(n))\n",
    "        min_val = min(array[j][i] for j in range(n))\n",
    "        \n",
    "        # Scale the values in the column\n",
    "        for j in range(n):\n",
    "            array[j][i] = (array[j][i] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "149a359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common element in a list\n",
    "def majority_vote(neighbors):\n",
    "    # Return the element that appears most often in the list\n",
    "    return max(set(neighbors), key=neighbors.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9dee996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote_weighted(neighbors):\n",
    "    hashmap = {}\n",
    "    for value, weight in neighbors:\n",
    "        # If the element is already in the dictionary, add its weight to the total\n",
    "        if weight in hashmap:\n",
    "            hashmap[weight] += 1/value\n",
    "        # If the element is not in the dictionary, add it and its weight\n",
    "        else:\n",
    "            hashmap[weight] = 1/value\n",
    "    \n",
    "    # Return the element with the highest weight\n",
    "    return max(hashmap, key=hashmap.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f55ad205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-nearest neighbors classification on the given data\n",
    "def knn(X_train, y_train, X_test, y_test, k_array, standard):\n",
    "    # Encode the personality types\n",
    "    y_train = [encode_personality_type(y) for y in y_train]\n",
    "    y_test = [encode_personality_type(y) for y in y_test]\n",
    "    \n",
    "    neighbors = []\n",
    "    for x in X_test:\n",
    "        # Calculate the distances between the test sample and the training samples\n",
    "        distances = (np.sum((x - X_train)**2, axis=1))**(1/2)\n",
    "\n",
    "        # Sort the training samples by distance\n",
    "        if standard:\n",
    "            y_sorted = [y for _, y in sorted(zip(distances,y_train))]\n",
    "        else:\n",
    "            y_sorted = [y for y in sorted(zip(distances,y_train))]\n",
    "            \n",
    "        # Add the sorted list of neighbors to the list\n",
    "        neighbors.append(y_sorted)\n",
    "        \n",
    "    accuracies, precisions, recalls = [], [], []\n",
    "    \n",
    "    nearest_neighbors = []\n",
    "    for k in k_array:\n",
    "        nearest_neighbors.append([n[:k] for n in neighbors])\n",
    "    \n",
    "    # Calculate the metrics for each value of k\n",
    "    for n in nearest_neighbors:\n",
    "        accuracy, precision, recall = metrics(X_train, y_train, X_test, y_test, n, standard)\n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "    return accuracies, precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989938a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(X_train, y_train, X_test, y_test, neighbors, standard):\n",
    "    # Use the majority vote function to classify the test samples\n",
    "    if standard:\n",
    "        y_pred = list(map(majority_vote, neighbors))\n",
    "    else:\n",
    "        y_pred = list(map(majority_vote_weighted, neighbors))\n",
    "    \n",
    "    true = 0\n",
    "    for i in range(len(y_test)):\n",
    "        # If the sample is correctly classified, increment the counter\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            true += 1\n",
    "    \n",
    "    # Calculate the accuracy     \n",
    "    accuracy = true / len(y_test)\n",
    "    precisions, recalls = [], []\n",
    "\n",
    "    for types in personality_types:\n",
    "        # Encode the types label\n",
    "        types_encoded = encode_personality_type(types)\n",
    "        \n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i] == types_encoded:\n",
    "                if y_pred[i] == y_test[i]:\n",
    "                    # If the sample is correctly classified, increment the true positive counter\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    # If the sample is misclassified, increment the false negative counter\n",
    "                    FN += 1\n",
    "            if y_pred[i] == types_encoded:\n",
    "                if y_test[i] != y_pred[i]:\n",
    "                    # If the sample is misclassified, increment the false positive counter\n",
    "                    FP += 1\n",
    "        \n",
    "        # Calculate the recall and precision for the personality type       \n",
    "        recall = TP/(TP+FN)\n",
    "        precision = TP/(TP+FP)\n",
    "        \n",
    "        # Add the recall and precision to the lists\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "    return accuracy, precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91bdd010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "def print1(accuracies, precisions, recalls):\n",
    "    print(\"Accuracies: \")\n",
    "    for i in accuracies:\n",
    "        print(i, end = \" \")\n",
    "    \n",
    "    print(\"\\n\\nPrecisions: \")\n",
    "    for i in precisions:\n",
    "        print(i)\n",
    "    \n",
    "    print(\"\\nRecalls: \")\n",
    "    for i in recalls:\n",
    "        print(i)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72b350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_array = [1,3,5,7,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c62d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: \n",
      "0.9616666666666667 0.9833333333333333 0.9841666666666666 0.9833333333333333 0.9825 \n",
      "\n",
      "Precisions: \n",
      "[0.9620253164556962, 0.8902439024390244, 0.9285714285714286, 0.975609756097561, 0.9753086419753086, 0.9662921348314607, 0.9473684210526315, 0.9605263157894737, 0.9866666666666667, 0.9692307692307692, 0.9875, 0.958904109589041, 1.0, 0.9861111111111112, 0.9210526315789473, 0.9696969696969697]\n",
      "[0.9871794871794872, 0.9868421052631579, 0.9636363636363636, 0.9878048780487805, 0.9761904761904762, 0.9888888888888889, 1.0, 0.9863013698630136, 0.9868421052631579, 0.9565217391304348, 0.9876543209876543, 0.9726027397260274, 1.0, 1.0, 0.9487179487179487, 1.0]\n",
      "[0.9746835443037974, 0.9868421052631579, 0.9473684210526315, 1.0, 0.9759036144578314, 0.978021978021978, 1.0, 0.9864864864864865, 0.9868421052631579, 0.9701492537313433, 0.9876543209876543, 0.9861111111111112, 1.0, 1.0, 0.961038961038961, 1.0]\n",
      "[0.9625, 0.9868421052631579, 0.9818181818181818, 1.0, 0.9759036144578314, 0.9777777777777777, 1.0, 0.9864864864864865, 0.9868421052631579, 0.9701492537313433, 0.9876543209876543, 0.9861111111111112, 1.0, 0.9864864864864865, 0.9487179487179487, 1.0]\n",
      "[0.9625, 0.9868421052631579, 0.9642857142857143, 1.0, 0.975609756097561, 0.9777777777777777, 1.0, 0.9864864864864865, 1.0, 0.9701492537313433, 0.9876543209876543, 0.9861111111111112, 1.0, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9743589743589743, 0.9733333333333334, 0.9629629629629629, 0.9876543209876543, 0.9294117647058824, 0.9555555555555556, 0.9863013698630136, 0.9733333333333334, 0.9736842105263158, 0.9402985074626866, 0.9518072289156626, 0.958904109589041, 0.972972972972973, 0.9726027397260274, 0.9333333333333333, 0.9411764705882353]\n",
      "[0.9871794871794872, 1.0, 0.9814814814814815, 1.0, 0.9647058823529412, 0.9888888888888889, 0.9863013698630136, 0.96, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 1.0, 1.0, 0.9866666666666667, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9529411764705882, 0.9888888888888889, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 1.0, 1.0, 0.9866666666666667, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9529411764705882, 0.9777777777777777, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9411764705882353, 0.9777777777777777, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.9675 0.9766666666666667 0.9791666666666666 0.9791666666666666 0.98 \n",
      "\n",
      "Precisions: \n",
      "[0.9878048780487805, 0.9381443298969072, 0.9420289855072463, 1.0, 0.9285714285714286, 0.9142857142857143, 0.9615384615384616, 0.9736842105263158, 0.9523809523809523, 0.974025974025974, 0.9827586206896551, 0.9534883720930233, 1.0, 1.0, 1.0, 0.987012987012987]\n",
      "[0.9761904761904762, 0.978494623655914, 0.9411764705882353, 0.9591836734693877, 0.9014084507042254, 0.9692307692307692, 1.0, 0.974025974025974, 0.9534883720930233, 1.0, 1.0, 0.9761904761904762, 1.0, 1.0, 1.0, 0.9871794871794872]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9701492537313433, 0.9591836734693877, 0.9154929577464789, 0.9402985074626866, 1.0, 0.974025974025974, 0.9529411764705882, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9761904761904762, 0.978494623655914, 0.9701492537313433, 0.9591836734693877, 0.9285714285714286, 0.9411764705882353, 0.9868421052631579, 0.974025974025974, 0.9642857142857143, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.9680851063829787, 0.9701492537313433, 0.9591836734693877, 0.9285714285714286, 0.9411764705882353, 0.9868421052631579, 0.9868421052631579, 0.9647058823529412, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9759036144578314, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.961038961038961, 0.963855421686747, 0.9493670886075949, 1.0, 0.9879518072289156, 0.9242424242424242, 0.9545454545454546, 0.9545454545454546, 0.926829268292683]\n",
      "[0.9879518072289156, 1.0, 0.9846153846153847, 0.9791666666666666, 0.9552238805970149, 0.9545454545454546, 0.974025974025974, 0.974025974025974, 0.9879518072289156, 0.9746835443037974, 1.0, 0.9879518072289156, 0.9393939393939394, 1.0, 0.9772727272727273, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9545454545454546, 0.974025974025974, 0.974025974025974, 0.9759036144578314, 0.9746835443037974, 1.0, 1.0, 0.9545454545454546, 1.0, 0.9772727272727273, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.974025974025974, 0.9759036144578314, 0.9746835443037974, 1.0, 1.0, 0.9696969696969697, 0.9886363636363636, 0.9659090909090909, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.974025974025974, 0.9879518072289156, 0.9746835443037974, 1.0, 1.0, 0.9696969696969697, 1.0, 0.9659090909090909, 0.926829268292683]\n",
      "\n",
      "Accuracies: \n",
      "0.9708333333333333 0.9825 0.9858333333333333 0.9866666666666667 0.9841666666666666 \n",
      "\n",
      "Precisions: \n",
      "[0.9868421052631579, 0.9696969696969697, 0.9861111111111112, 0.975, 0.9726027397260274, 0.9868421052631579, 0.9726027397260274, 0.9759036144578314, 0.9848484848484849, 0.9871794871794872, 0.9367088607594937, 0.948051948051948, 0.9634146341463414, 0.9882352941176471, 0.9322033898305084, 0.96]\n",
      "[0.9868421052631579, 0.9696969696969697, 0.9864864864864865, 0.9746835443037974, 0.9863013698630136, 1.0, 0.9863013698630136, 0.9772727272727273, 0.971830985915493, 0.975, 1.0, 0.9733333333333334, 0.9875, 1.0, 0.9649122807017544, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.9733333333333334, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9772727272727273, 0.971830985915493, 0.9875, 1.0, 0.9733333333333334, 0.9876543209876543, 1.0, 0.9821428571428571, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.9733333333333334, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9885057471264368, 0.9857142857142858, 0.9875, 1.0, 0.9733333333333334, 0.9878048780487805, 1.0, 0.9649122807017544, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.972972972972973, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9885057471264368, 0.9583333333333334, 0.9875, 1.0, 0.9733333333333334, 0.9875, 1.0, 0.9649122807017544, 0.9594594594594594]\n",
      "\n",
      "Recalls: \n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 0.9873417721518988, 0.9726027397260274, 0.974025974025974, 0.9594594594594594, 0.9418604651162791, 0.9285714285714286, 0.9625, 1.0, 1.0, 0.9753086419753086, 0.9655172413793104, 0.9482758620689655, 0.9863013698630136]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 0.9746835443037974, 0.9863013698630136, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.975, 1.0, 1.0, 0.9753086419753086, 0.9770114942528736, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 1.0, 0.9863013698630136, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9770114942528736, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 1.0, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9863013698630136, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9753086419753086, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "\n",
      "Accuracies: \n",
      "0.9716666666666667 0.9825 0.9866666666666667 0.9883333333333333 0.99 \n",
      "\n",
      "Precisions: \n",
      "[0.9662921348314607, 0.9506172839506173, 0.9743589743589743, 0.975609756097561, 0.9864864864864865, 0.9634146341463414, 0.9565217391304348, 0.972972972972973, 1.0, 0.9594594594594594, 1.0, 0.9206349206349206, 0.9661016949152542, 1.0, 0.987012987012987, 0.9571428571428572]\n",
      "[0.9666666666666667, 0.975, 0.963855421686747, 0.963855421686747, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.972972972972973, 1.0, 0.9672131147540983, 0.9827586206896551, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9647058823529412, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9672131147540983, 0.9661016949152542, 1.0, 0.974025974025974, 1.0]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9647058823529412, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9833333333333333, 0.9830508474576272, 1.0, 0.9743589743589743, 1.0]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9761904761904762, 1.0, 1.0, 0.9857142857142858, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9833333333333333, 0.9830508474576272, 1.0, 0.987012987012987, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9885057471264368, 0.9625, 0.926829268292683, 0.975609756097561, 0.9605263157894737, 0.9634146341463414, 0.9428571428571428, 1.0, 0.972972972972973, 0.9861111111111112, 0.9866666666666667, 0.9508196721311475, 0.9661016949152542, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.975, 0.975609756097561, 0.975609756097561, 0.9868421052631579, 0.9634146341463414, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9661016949152542, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 1.0, 0.975609756097561, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9661016949152542, 1.0, 0.9615384615384616, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 1.0, 0.975609756097561, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 1.0, 0.9878048780487805, 0.9857142857142858, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.97 0.9816666666666667 0.9883333333333333 0.9866666666666667 0.9858333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9888888888888889, 1.0, 0.95, 0.9836065573770492, 0.9577464788732394, 0.9696969696969697, 0.9655172413793104, 0.9384615384615385, 0.9466666666666667, 1.0, 0.9859154929577465, 0.9873417721518988, 0.971830985915493, 0.9629629629629629, 0.9402985074626866, 0.9594594594594594]\n",
      "[0.989010989010989, 1.0, 0.9625, 0.9836065573770492, 0.9583333333333334, 0.984375, 1.0, 0.9841269841269841, 0.9473684210526315, 1.0, 0.9866666666666667, 0.9753086419753086, 0.9861111111111112, 0.975, 0.9692307692307692, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9753086419753086, 0.9836065573770492, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.972972972972973, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 1.0, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9634146341463414, 0.9836065573770492, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.972972972972973, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9634146341463414, 0.9836065573770492, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.96, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 0.984375, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.967391304347826, 0.9550561797752809, 0.9620253164556962, 0.9836065573770492, 0.9444444444444444, 1.0, 0.9882352941176471, 0.9682539682539683, 0.9861111111111112, 0.9506172839506173, 0.9333333333333333, 0.975, 0.9452054794520548, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9662921348314607, 0.9746835443037974, 0.9836065573770492, 0.9583333333333334, 0.984375, 0.9764705882352941, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9662921348314607, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 1.0, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 1.0]\n",
      "[0.9782608695652174, 0.9662921348314607, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9662921348314607, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9722222222222222]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Classify the test samples using k-nn with the standard approach\n",
    "    accuracies, precisions, recalls = knn(X_trains[i], y_trains[i], X_tests[i], y_tests[i], k_array, True)\n",
    "    print1(accuracies, precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "722ee3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: \n",
      "0.9616666666666667 0.9841666666666666 0.985 0.985 0.9833333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9620253164556962, 0.8902439024390244, 0.9285714285714286, 0.975609756097561, 0.9753086419753086, 0.9662921348314607, 0.9473684210526315, 0.9605263157894737, 0.9866666666666667, 0.9692307692307692, 0.9875, 0.958904109589041, 1.0, 0.9861111111111112, 0.9210526315789473, 0.9696969696969697]\n",
      "[0.9871794871794872, 0.9868421052631579, 0.9642857142857143, 1.0, 0.9759036144578314, 0.978021978021978, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9705882352941176, 0.9876543209876543, 0.9861111111111112, 1.0, 1.0, 0.9487179487179487, 1.0]\n",
      "[0.9871794871794872, 0.9868421052631579, 0.9473684210526315, 1.0, 0.9759036144578314, 0.978021978021978, 1.0, 0.9864864864864865, 0.9868421052631579, 0.9705882352941176, 0.9876543209876543, 0.9861111111111112, 1.0, 1.0, 0.961038961038961, 1.0]\n",
      "[0.9871794871794872, 0.9868421052631579, 0.9818181818181818, 1.0, 0.9759036144578314, 0.978021978021978, 1.0, 0.9864864864864865, 0.9868421052631579, 0.9705882352941176, 0.9876543209876543, 0.9861111111111112, 1.0, 0.9864864864864865, 0.9487179487179487, 1.0]\n",
      "[0.9746835443037974, 0.9868421052631579, 0.9818181818181818, 1.0, 0.975609756097561, 0.978021978021978, 1.0, 0.9864864864864865, 0.9868421052631579, 0.9701492537313433, 0.9876543209876543, 0.9861111111111112, 1.0, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9743589743589743, 0.9733333333333334, 0.9629629629629629, 0.9876543209876543, 0.9294117647058824, 0.9555555555555556, 0.9863013698630136, 0.9733333333333334, 0.9736842105263158, 0.9402985074626866, 0.9518072289156626, 0.958904109589041, 0.972972972972973, 0.9726027397260274, 0.9333333333333333, 0.9411764705882353]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9529411764705882, 0.9888888888888889, 0.9863013698630136, 0.9733333333333334, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 1.0, 1.0, 0.9866666666666667, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9529411764705882, 0.9888888888888889, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 1.0, 1.0, 0.9866666666666667, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9529411764705882, 0.9888888888888889, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9411764705882353, 0.9888888888888889, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.9675 0.9775 0.9791666666666666 0.98 0.98 \n",
      "\n",
      "Precisions: \n",
      "[0.9878048780487805, 0.9381443298969072, 0.9420289855072463, 1.0, 0.9285714285714286, 0.9142857142857143, 0.9615384615384616, 0.9736842105263158, 0.9523809523809523, 0.974025974025974, 0.9827586206896551, 0.9534883720930233, 1.0, 1.0, 1.0, 0.987012987012987]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9552238805970149, 0.9791666666666666, 0.9154929577464789, 0.9545454545454546, 0.974025974025974, 0.9620253164556962, 0.9529411764705882, 1.0, 1.0, 0.9761904761904762, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9701492537313433, 0.9591836734693877, 0.9154929577464789, 0.9402985074626866, 1.0, 0.9743589743589743, 0.9529411764705882, 1.0, 1.0, 0.9761904761904762, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9701492537313433, 0.9591836734693877, 0.9285714285714286, 0.9411764705882353, 0.9868421052631579, 0.974025974025974, 0.9642857142857143, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9701492537313433, 0.9591836734693877, 0.9285714285714286, 0.9411764705882353, 0.9868421052631579, 0.974025974025974, 0.9642857142857143, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9759036144578314, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.961038961038961, 0.963855421686747, 0.9493670886075949, 1.0, 0.9879518072289156, 0.9242424242424242, 0.9545454545454546, 0.9545454545454546, 0.926829268292683]\n",
      "[0.9879518072289156, 1.0, 0.9846153846153847, 0.9791666666666666, 0.9701492537313433, 0.9545454545454546, 0.974025974025974, 0.987012987012987, 0.9759036144578314, 0.9746835443037974, 1.0, 0.9879518072289156, 0.9393939393939394, 1.0, 0.9772727272727273, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9545454545454546, 0.974025974025974, 0.987012987012987, 0.9759036144578314, 0.9746835443037974, 1.0, 0.9879518072289156, 0.9545454545454546, 1.0, 0.9772727272727273, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.974025974025974, 0.9759036144578314, 0.9746835443037974, 1.0, 1.0, 0.9696969696969697, 1.0, 0.9659090909090909, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.974025974025974, 0.9759036144578314, 0.9746835443037974, 1.0, 1.0, 0.9696969696969697, 1.0, 0.9659090909090909, 0.9390243902439024]\n",
      "\n",
      "Accuracies: \n",
      "0.9708333333333333 0.9841666666666666 0.9858333333333333 0.9866666666666667 0.985 \n",
      "\n",
      "Precisions: \n",
      "[0.9868421052631579, 0.9696969696969697, 0.9861111111111112, 0.975, 0.9726027397260274, 0.9868421052631579, 0.9726027397260274, 0.9759036144578314, 0.9848484848484849, 0.9871794871794872, 0.9367088607594937, 0.948051948051948, 0.9634146341463414, 0.9882352941176471, 0.9322033898305084, 0.96]\n",
      "[1.0, 0.9696969696969697, 0.9864864864864865, 0.975, 0.9863013698630136, 1.0, 0.9863013698630136, 0.9772727272727273, 0.971830985915493, 0.9875, 1.0, 0.9733333333333334, 0.9875, 1.0, 0.9649122807017544, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.9733333333333334, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9772727272727273, 0.971830985915493, 0.9875, 1.0, 0.9733333333333334, 0.9876543209876543, 1.0, 0.9821428571428571, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.9733333333333334, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9885057471264368, 0.9857142857142858, 0.9875, 1.0, 0.9733333333333334, 0.9878048780487805, 1.0, 0.9649122807017544, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.972972972972973, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9885057471264368, 0.971830985915493, 0.9875, 1.0, 0.9733333333333334, 0.9876543209876543, 1.0, 0.9649122807017544, 0.9594594594594594]\n",
      "\n",
      "Recalls: \n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 0.9873417721518988, 0.9726027397260274, 0.974025974025974, 0.9594594594594594, 0.9418604651162791, 0.9285714285714286, 0.9625, 1.0, 1.0, 0.9753086419753086, 0.9655172413793104, 0.9482758620689655, 0.9863013698630136]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 0.9873417721518988, 0.9863013698630136, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9753086419753086, 0.9770114942528736, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 1.0, 0.9863013698630136, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9770114942528736, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 1.0, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9863013698630136, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "\n",
      "Accuracies: \n",
      "0.9716666666666667 0.9841666666666666 0.9883333333333333 0.9883333333333333 0.99 \n",
      "\n",
      "Precisions: \n",
      "[0.9662921348314607, 0.9506172839506173, 0.9743589743589743, 0.975609756097561, 0.9864864864864865, 0.9634146341463414, 0.9565217391304348, 0.972972972972973, 1.0, 0.9594594594594594, 1.0, 0.9206349206349206, 0.9661016949152542, 1.0, 0.987012987012987, 0.9571428571428572]\n",
      "[0.9775280898876404, 0.975, 0.9753086419753086, 0.9759036144578314, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9571428571428572]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9761904761904762, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 1.0]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9647058823529412, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9833333333333333, 0.9830508474576272, 1.0, 0.9743589743589743, 1.0]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9761904761904762, 1.0, 1.0, 0.9857142857142858, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9833333333333333, 0.9830508474576272, 1.0, 0.987012987012987, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9885057471264368, 0.9625, 0.926829268292683, 0.975609756097561, 0.9605263157894737, 0.9634146341463414, 0.9428571428571428, 1.0, 0.972972972972973, 0.9861111111111112, 0.9866666666666667, 0.9508196721311475, 0.9661016949152542, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.975, 0.9634146341463414, 0.9878048780487805, 1.0, 0.9634146341463414, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 1.0, 0.975609756097561, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 1.0, 0.975609756097561, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 1.0, 0.9878048780487805, 0.9857142857142858, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.97 0.9833333333333333 0.9875 0.9866666666666667 0.9866666666666667 \n",
      "\n",
      "Precisions: \n",
      "[0.9888888888888889, 1.0, 0.95, 0.9836065573770492, 0.9577464788732394, 0.9696969696969697, 0.9655172413793104, 0.9384615384615385, 0.9466666666666667, 1.0, 0.9859154929577465, 0.9873417721518988, 0.971830985915493, 0.9629629629629629, 0.9402985074626866, 0.9594594594594594]\n",
      "[0.989010989010989, 1.0, 0.9625, 0.9836065573770492, 0.9583333333333334, 0.9846153846153847, 1.0, 0.9841269841269841, 0.96, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 0.9692307692307692, 1.0]\n",
      "[0.989010989010989, 1.0, 0.975, 0.9836065573770492, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.972972972972973, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9634146341463414, 0.9836065573770492, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.972972972972973, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9634146341463414, 0.9836065573770492, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.972972972972973, 1.0, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.975, 0.984375, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.967391304347826, 0.9550561797752809, 0.9620253164556962, 0.9836065573770492, 0.9444444444444444, 1.0, 0.9882352941176471, 0.9682539682539683, 0.9861111111111112, 0.9506172839506173, 0.9333333333333333, 0.975, 0.9452054794520548, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9662921348314607, 0.9746835443037974, 0.9836065573770492, 0.9583333333333334, 1.0, 0.9764705882352941, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9662921348314607, 0.9873417721518988, 0.9836065573770492, 0.9722222222222222, 1.0, 1.0, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 1.0]\n",
      "[0.9782608695652174, 0.9662921348314607, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9662921348314607, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 1.0, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Classify the test samples using k-nn with the standard approach\n",
    "    accuracies, precisions, recalls = knn(X_trains[i] ,  y_trains[i] , X_tests[i] , y_tests[i], k_array, False)\n",
    "    print1(accuracies, precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daff01dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: \n",
      "0.955 0.9733333333333334 0.9783333333333334 0.98 0.9833333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9487179487179487, 0.9240506329113924, 0.9473684210526315, 0.9642857142857143, 0.987012987012987, 0.9438202247191011, 0.96, 0.9726027397260274, 0.9866666666666667, 0.9538461538461539, 0.9873417721518988, 0.9466666666666667, 0.948051948051948, 0.9452054794520548, 0.8846153846153846, 0.9848484848484849]\n",
      "[0.9390243902439024, 0.974025974025974, 0.9642857142857143, 0.9875, 0.9876543209876543, 0.9775280898876404, 1.0, 0.9861111111111112, 0.9868421052631579, 0.9558823529411765, 0.9876543209876543, 0.9342105263157895, 1.0, 0.972972972972973, 0.9240506329113924, 1.0]\n",
      "[0.9390243902439024, 0.974025974025974, 0.9818181818181818, 0.9875, 0.975609756097561, 0.9777777777777777, 1.0, 0.9859154929577465, 0.9868421052631579, 0.9705882352941176, 0.9876543209876543, 0.9726027397260274, 1.0, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "[0.9625, 0.9868421052631579, 0.9818181818181818, 1.0, 0.963855421686747, 0.9777777777777777, 1.0, 0.9861111111111112, 0.9868421052631579, 0.9701492537313433, 0.9876543209876543, 0.9726027397260274, 0.9864864864864865, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "[0.9746835443037974, 0.9868421052631579, 0.9818181818181818, 1.0, 0.9759036144578314, 0.9777777777777777, 1.0, 0.9864864864864865, 1.0, 0.9705882352941176, 0.9876543209876543, 0.9726027397260274, 0.9864864864864865, 0.9864864864864865, 0.9487179487179487, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9487179487179487, 0.9733333333333334, 1.0, 1.0, 0.8941176470588236, 0.9333333333333333, 0.9863013698630136, 0.9466666666666667, 0.9736842105263158, 0.9253731343283582, 0.9397590361445783, 0.9726027397260274, 0.9864864864864865, 0.9452054794520548, 0.92, 0.9558823529411765]\n",
      "[0.9871794871794872, 1.0, 1.0, 0.9753086419753086, 0.9411764705882353, 0.9666666666666667, 0.9863013698630136, 0.9466666666666667, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 0.9594594594594594, 0.9863013698630136, 0.9733333333333334, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 0.9753086419753086, 0.9411764705882353, 0.9777777777777777, 1.0, 0.9333333333333333, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 0.9876543209876543, 0.9411764705882353, 0.9777777777777777, 1.0, 0.9466666666666667, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "[0.9871794871794872, 1.0, 1.0, 0.9876543209876543, 0.9529411764705882, 0.9777777777777777, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.9441666666666667 0.9683333333333334 0.9741666666666666 0.9791666666666666 0.9808333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9302325581395349, 0.9278350515463918, 0.9117647058823529, 0.9787234042553191, 0.8783783783783784, 0.9508196721311475, 0.9594594594594594, 0.9605263157894737, 0.9204545454545454, 0.9615384615384616, 0.9824561403508771, 0.9, 0.9516129032258065, 0.9529411764705882, 0.9878048780487805, 0.9866666666666667]\n",
      "[0.9534883720930233, 0.9578947368421052, 0.9142857142857143, 0.9215686274509803, 0.9027777777777778, 0.9836065573770492, 0.9866666666666667, 0.974025974025974, 0.9529411764705882, 1.0, 1.0, 0.9534883720930233, 1.0, 1.0, 1.0, 0.9864864864864865]\n",
      "[0.9761904761904762, 0.9578947368421052, 0.9420289855072463, 0.9038461538461539, 0.9027777777777778, 0.9841269841269841, 0.9868421052631579, 0.9868421052631579, 0.9642857142857143, 1.0, 1.0, 0.9647058823529412, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9761904761904762, 0.9680851063829787, 0.9558823529411765, 0.94, 0.9285714285714286, 0.9848484848484849, 1.0, 0.9620253164556962, 0.963855421686747, 1.0, 1.0, 0.9761904761904762, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.9680851063829787, 0.9701492537313433, 0.9591836734693877, 0.9154929577464789, 0.9846153846153847, 1.0, 0.9620253164556962, 0.963855421686747, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.963855421686747, 0.989010989010989, 0.9538461538461539, 0.9583333333333334, 0.9701492537313433, 0.8787878787878788, 0.922077922077922, 0.948051948051948, 0.9759036144578314, 0.9493670886075949, 0.9824561403508771, 0.9759036144578314, 0.8939393939393939, 0.9204545454545454, 0.9204545454545454, 0.9024390243902439]\n",
      "[0.9879518072289156, 1.0, 0.9846153846153847, 0.9791666666666666, 0.9701492537313433, 0.9090909090909091, 0.961038961038961, 0.974025974025974, 0.9759036144578314, 0.9746835443037974, 1.0, 0.9879518072289156, 0.9242424242424242, 1.0, 0.9659090909090909, 0.8902439024390244]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9393939393939394, 0.974025974025974, 0.974025974025974, 0.9759036144578314, 0.9620253164556962, 1.0, 0.9879518072289156, 0.9545454545454546, 0.9886363636363636, 0.9545454545454546, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9848484848484849, 0.974025974025974, 0.987012987012987, 0.963855421686747, 0.9746835443037974, 1.0, 0.9879518072289156, 0.9696969696969697, 1.0, 0.9659090909090909, 0.926829268292683]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.987012987012987, 0.963855421686747, 0.9746835443037974, 1.0, 1.0, 0.9696969696969697, 1.0, 0.9772727272727273, 0.9390243902439024]\n",
      "\n",
      "Accuracies: \n",
      "0.9558333333333333 0.9766666666666667 0.9825 0.9858333333333333 0.9833333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9487179487179487, 0.9552238805970149, 0.9583333333333334, 0.9404761904761905, 0.9714285714285714, 0.9375, 0.9852941176470589, 0.9634146341463414, 0.9710144927536232, 0.972972972972973, 0.9736842105263158, 0.8674698795180723, 0.9518072289156626, 0.9880952380952381, 0.9298245614035088, 0.9863013698630136]\n",
      "[0.974025974025974, 0.9696969696969697, 0.9726027397260274, 0.9634146341463414, 0.9857142857142858, 1.0, 0.9726027397260274, 0.9883720930232558, 0.9583333333333334, 0.9875, 0.9866666666666667, 0.935064935064935, 0.975609756097561, 1.0, 0.9642857142857143, 0.9859154929577465]\n",
      "[1.0, 0.9846153846153847, 0.9594594594594594, 0.9753086419753086, 1.0, 1.0, 0.972972972972973, 0.9772727272727273, 0.9857142857142858, 0.9875, 1.0, 0.9733333333333334, 0.9759036144578314, 1.0, 0.9482758620689655, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.9733333333333334, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9772727272727273, 0.971830985915493, 0.9875, 1.0, 0.9733333333333334, 0.9876543209876543, 1.0, 0.9649122807017544, 0.9861111111111112]\n",
      "[0.9868421052631579, 0.9846153846153847, 0.9726027397260274, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9883720930232558, 0.971830985915493, 0.9875, 1.0, 0.9733333333333334, 0.975609756097561, 0.9885057471264368, 0.9649122807017544, 0.9726027397260274]\n",
      "\n",
      "Recalls: \n",
      "[0.961038961038961, 0.9846153846153847, 0.9452054794520548, 1.0, 0.9315068493150684, 0.974025974025974, 0.9054054054054054, 0.9186046511627907, 0.9571428571428572, 0.9, 1.0, 0.9863013698630136, 0.9753086419753086, 0.9540229885057471, 0.9137931034482759, 0.9863013698630136]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 1.0, 0.9452054794520548, 0.974025974025974, 0.9594594594594594, 0.9883720930232558, 0.9857142857142858, 0.9875, 1.0, 0.9863013698630136, 0.9876543209876543, 0.9770114942528736, 0.9310344827586207, 0.958904109589041]\n",
      "[0.961038961038961, 0.9846153846153847, 0.9726027397260274, 1.0, 0.958904109589041, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 1.0, 0.9770114942528736, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 1.0, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 0.9883720930232558, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "\n",
      "Accuracies: \n",
      "0.955 0.9783333333333334 0.9816666666666667 0.9875 0.9866666666666667 \n",
      "\n",
      "Precisions: \n",
      "[0.9555555555555556, 0.9512195121951219, 0.9866666666666667, 0.9634146341463414, 0.96, 0.975, 0.9393939393939394, 0.9452054794520548, 1.0, 0.9459459459459459, 0.9866666666666667, 0.8507462686567164, 0.9322033898305084, 0.9875, 0.9493670886075949, 0.9295774647887324]\n",
      "[0.9560439560439561, 0.9753086419753086, 0.9753086419753086, 0.9518072289156626, 1.0, 0.9875, 0.9848484848484849, 0.9863013698630136, 1.0, 0.96, 1.0, 0.9365079365079365, 0.9827586206896551, 1.0, 0.9620253164556962, 1.0]\n",
      "[0.9666666666666667, 0.9875, 0.9875, 0.9759036144578314, 1.0, 0.975609756097561, 0.9852941176470589, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9516129032258065, 0.9344262295081968, 1.0, 0.961038961038961, 1.0]\n",
      "[0.9775280898876404, 0.9875, 0.9878048780487805, 0.9761904761904762, 1.0, 0.9878048780487805, 0.9852941176470589, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9833333333333333, 0.9830508474576272, 1.0, 0.9620253164556962, 1.0]\n",
      "[0.9666666666666667, 0.9873417721518988, 0.9878048780487805, 0.9647058823529412, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9833333333333333, 0.9830508474576272, 1.0, 0.9620253164556962, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9885057471264368, 0.975, 0.9024390243902439, 0.9634146341463414, 0.9473684210526315, 0.9512195121951219, 0.8857142857142857, 0.9583333333333334, 0.972972972972973, 0.9722222222222222, 0.9866666666666667, 0.9344262295081968, 0.9322033898305084, 0.9634146341463414, 0.9615384615384616, 0.9705882352941176]\n",
      "[1.0, 0.9875, 0.9634146341463414, 0.9634146341463414, 0.9868421052631579, 0.9634146341463414, 0.9285714285714286, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9661016949152542, 0.9878048780487805, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9634146341463414, 0.9878048780487805, 0.9868421052631579, 0.975609756097561, 0.9571428571428572, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9661016949152542, 1.0, 0.9487179487179487, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9878048780487805, 1.0, 0.9868421052631579, 0.9878048780487805, 0.9571428571428572, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.975, 0.9878048780487805, 1.0, 0.9868421052631579, 0.975609756097561, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.9616666666666667 0.9791666666666666 0.9833333333333333 0.985 0.9841666666666666 \n",
      "\n",
      "Precisions: \n",
      "[0.9777777777777777, 0.9761904761904762, 0.9390243902439024, 0.9523809523809523, 0.9315068493150684, 0.984375, 0.9318181818181818, 0.9841269841269841, 0.9714285714285714, 1.0, 0.948051948051948, 0.9875, 0.958904109589041, 0.9512195121951219, 0.9523809523809523, 0.9459459459459459]\n",
      "[0.989010989010989, 1.0, 0.9404761904761905, 0.9523809523809523, 0.9722222222222222, 0.984375, 1.0, 0.9838709677419355, 0.9594594594594594, 1.0, 0.9866666666666667, 0.9875, 0.9722222222222222, 0.9512195121951219, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9753086419753086, 0.9523809523809523, 0.9859154929577465, 0.9696969696969697, 1.0, 0.9841269841269841, 0.9594594594594594, 1.0, 0.9866666666666667, 0.9875, 0.972972972972973, 0.9629629629629629, 1.0, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9753086419753086, 0.967741935483871, 0.9859154929577465, 0.9846153846153847, 0.9880952380952381, 0.9841269841269841, 0.9861111111111112, 1.0, 0.9866666666666667, 0.9875, 0.972972972972973, 0.9629629629629629, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9634146341463414, 0.967741935483871, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.9594594594594594, 1.0, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9629629629629629, 1.0, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9565217391304348, 0.9213483146067416, 0.9746835443037974, 0.9836065573770492, 0.9444444444444444, 0.984375, 0.9647058823529412, 0.9841269841269841, 0.9444444444444444, 0.9135802469135802, 0.9733333333333334, 0.9875, 0.958904109589041, 0.9873417721518988, 0.9523809523809523, 0.9722222222222222]\n",
      "[0.9782608695652174, 0.9550561797752809, 1.0, 0.9836065573770492, 0.9722222222222222, 0.984375, 0.9647058823529412, 0.9682539682539683, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.958904109589041, 0.9873417721518988, 1.0, 0.9722222222222222]\n",
      "[0.9782608695652174, 0.9438202247191011, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9764705882352941, 0.9841269841269841, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9550561797752809, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9764705882352941, 0.9841269841269841, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 1.0]\n",
      "[0.9782608695652174, 0.9438202247191011, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9873417721518988, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scale(array)\n",
    "five_fold(array)\n",
    "\n",
    "for i in range(5):\n",
    "    # Classify the test samples using k-nn with the standard approach and scaling\n",
    "    accuracies, precisions, recalls = knn(X_trains[i] ,  y_trains[i] , X_tests[i] , y_tests[i], k_array, True)\n",
    "    print1(accuracies, precisions, recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a7942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies: \n",
      "0.955 0.9758333333333333 0.9808333333333333 0.9816666666666667 0.9833333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9487179487179487, 0.9240506329113924, 0.9473684210526315, 0.9642857142857143, 0.987012987012987, 0.9438202247191011, 0.96, 0.9726027397260274, 0.9866666666666667, 0.9538461538461539, 0.9873417721518988, 0.9466666666666667, 0.948051948051948, 0.9452054794520548, 0.8846153846153846, 0.9848484848484849]\n",
      "[0.9506172839506173, 0.9866666666666667, 0.9642857142857143, 1.0, 0.9876543209876543, 0.9666666666666667, 1.0, 0.9864864864864865, 1.0, 0.9558823529411765, 0.9876543209876543, 0.9594594594594594, 0.972972972972973, 0.972972972972973, 0.9240506329113924, 1.0]\n",
      "[0.9625, 0.9868421052631579, 0.9818181818181818, 1.0, 0.975609756097561, 0.9775280898876404, 0.9864864864864865, 0.9861111111111112, 0.9868421052631579, 0.9705882352941176, 0.9876543209876543, 0.9861111111111112, 0.9864864864864865, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "[0.9746835443037974, 0.9868421052631579, 0.9818181818181818, 1.0, 0.975609756097561, 0.9775280898876404, 0.9864864864864865, 0.9863013698630136, 0.9868421052631579, 0.9705882352941176, 0.9876543209876543, 0.9861111111111112, 0.9864864864864865, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "[0.9746835443037974, 0.9868421052631579, 0.9818181818181818, 1.0, 0.975609756097561, 0.9777777777777777, 1.0, 0.9864864864864865, 1.0, 0.9705882352941176, 0.9876543209876543, 0.9861111111111112, 0.9864864864864865, 0.9864864864864865, 0.9367088607594937, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9487179487179487, 0.9733333333333334, 1.0, 1.0, 0.8941176470588236, 0.9333333333333333, 0.9863013698630136, 0.9466666666666667, 0.9736842105263158, 0.9253731343283582, 0.9397590361445783, 0.9726027397260274, 0.9864864864864865, 0.9452054794520548, 0.92, 0.9558823529411765]\n",
      "[0.9871794871794872, 0.9866666666666667, 1.0, 0.9753086419753086, 0.9411764705882353, 0.9666666666666667, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9701492537313433, 0.963855421686747, 0.9726027397260274, 0.972972972972973, 0.9863013698630136, 0.9733333333333334, 0.9705882352941176]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9411764705882353, 0.9666666666666667, 1.0, 0.9466666666666667, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9411764705882353, 0.9666666666666667, 1.0, 0.96, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "[0.9871794871794872, 1.0, 1.0, 1.0, 0.9411764705882353, 0.9777777777777777, 1.0, 0.9733333333333334, 0.9868421052631579, 0.9850746268656716, 0.963855421686747, 0.9726027397260274, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.9441666666666667 0.9725 0.9766666666666667 0.9791666666666666 0.9825 \n",
      "\n",
      "Precisions: \n",
      "[0.9302325581395349, 0.9278350515463918, 0.9117647058823529, 0.9787234042553191, 0.8783783783783784, 0.9508196721311475, 0.9594594594594594, 0.9605263157894737, 0.9204545454545454, 0.9615384615384616, 0.9824561403508771, 0.9, 0.9516129032258065, 0.9529411764705882, 0.9878048780487805, 0.9866666666666667]\n",
      "[0.9647058823529412, 0.9680851063829787, 0.9552238805970149, 0.9591836734693877, 0.9154929577464789, 0.967741935483871, 0.9868421052631579, 0.9620253164556962, 0.9529411764705882, 1.0, 1.0, 0.9534883720930233, 0.96875, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9558823529411765, 0.94, 0.9027777777777778, 0.96875, 0.9868421052631579, 0.9743589743589743, 0.9642857142857143, 1.0, 1.0, 0.9540229885057471, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9761904761904762, 0.9680851063829787, 0.9701492537313433, 0.9591836734693877, 0.9285714285714286, 0.9696969696969697, 0.9868421052631579, 0.9620253164556962, 0.963855421686747, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.9879518072289156, 0.978494623655914, 0.9701492537313433, 0.9591836734693877, 0.9285714285714286, 0.9848484848484849, 1.0, 0.9620253164556962, 0.963855421686747, 1.0, 1.0, 0.9764705882352941, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.963855421686747, 0.989010989010989, 0.9538461538461539, 0.9583333333333334, 0.9701492537313433, 0.8787878787878788, 0.922077922077922, 0.948051948051948, 0.9759036144578314, 0.9493670886075949, 0.9824561403508771, 0.9759036144578314, 0.8939393939393939, 0.9204545454545454, 0.9204545454545454, 0.9024390243902439]\n",
      "[0.9879518072289156, 1.0, 0.9846153846153847, 0.9791666666666666, 0.9701492537313433, 0.9090909090909091, 0.974025974025974, 0.987012987012987, 0.9759036144578314, 0.9746835443037974, 1.0, 0.9879518072289156, 0.9393939393939394, 1.0, 0.9659090909090909, 0.9146341463414634]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9393939393939394, 0.974025974025974, 0.987012987012987, 0.9759036144578314, 0.9620253164556962, 1.0, 1.0, 0.9393939393939394, 0.9886363636363636, 0.9772727272727273, 0.9390243902439024]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9696969696969697, 0.974025974025974, 0.987012987012987, 0.963855421686747, 0.9746835443037974, 1.0, 1.0, 0.9545454545454546, 1.0, 0.9772727272727273, 0.926829268292683]\n",
      "[0.9879518072289156, 1.0, 1.0, 0.9791666666666666, 0.9701492537313433, 0.9848484848484849, 0.974025974025974, 0.987012987012987, 0.963855421686747, 0.9746835443037974, 1.0, 1.0, 0.9696969696969697, 1.0, 0.9772727272727273, 0.9512195121951219]\n",
      "\n",
      "Accuracies: \n",
      "0.9558333333333333 0.9816666666666667 0.9816666666666667 0.985 0.9833333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9487179487179487, 0.9552238805970149, 0.9583333333333334, 0.9404761904761905, 0.9714285714285714, 0.9375, 0.9852941176470589, 0.9634146341463414, 0.9710144927536232, 0.972972972972973, 0.9736842105263158, 0.8674698795180723, 0.9518072289156626, 0.9880952380952381, 0.9298245614035088, 0.9863013698630136]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 0.9753086419753086, 1.0, 1.0, 0.9726027397260274, 0.9770114942528736, 0.9857142857142858, 0.9875, 1.0, 0.948051948051948, 0.963855421686747, 1.0, 0.9821428571428571, 0.9863013698630136]\n",
      "[1.0, 0.9846153846153847, 0.9722222222222222, 0.9634146341463414, 1.0, 1.0, 0.9726027397260274, 0.9662921348314607, 0.9857142857142858, 0.9875, 1.0, 0.9733333333333334, 0.9759036144578314, 1.0, 0.9482758620689655, 0.9726027397260274]\n",
      "[1.0, 0.9846153846153847, 0.972972972972973, 0.9634146341463414, 1.0, 1.0, 0.9863013698630136, 0.9885057471264368, 0.971830985915493, 0.9875, 1.0, 0.9864864864864865, 0.963855421686747, 1.0, 0.9649122807017544, 0.9861111111111112]\n",
      "[0.9868421052631579, 0.9846153846153847, 0.9726027397260274, 0.9753086419753086, 1.0, 1.0, 0.9863013698630136, 0.9883720930232558, 0.971830985915493, 0.9875, 1.0, 0.9864864864864865, 0.963855421686747, 0.9885057471264368, 0.9649122807017544, 0.9726027397260274]\n",
      "\n",
      "Recalls: \n",
      "[0.961038961038961, 0.9846153846153847, 0.9452054794520548, 1.0, 0.9315068493150684, 0.974025974025974, 0.9054054054054054, 0.9186046511627907, 0.9571428571428572, 0.9, 1.0, 0.9863013698630136, 0.9753086419753086, 0.9540229885057471, 0.9137931034482759, 0.9863013698630136]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 1.0, 0.958904109589041, 0.974025974025974, 0.9594594594594594, 0.9883720930232558, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9885057471264368, 0.9482758620689655, 0.9863013698630136]\n",
      "[0.961038961038961, 0.9846153846153847, 0.958904109589041, 1.0, 0.9726027397260274, 0.987012987012987, 0.9594594594594594, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 1.0, 0.9770114942528736, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9863013698630136, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 1.0, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "[0.974025974025974, 0.9846153846153847, 0.9726027397260274, 1.0, 0.9726027397260274, 0.987012987012987, 0.972972972972973, 0.9883720930232558, 0.9857142857142858, 0.9875, 1.0, 1.0, 0.9876543209876543, 0.9885057471264368, 0.9482758620689655, 0.9726027397260274]\n",
      "\n",
      "Accuracies: \n",
      "0.955 0.9783333333333334 0.9833333333333333 0.985 0.9858333333333333 \n",
      "\n",
      "Precisions: \n",
      "[0.9555555555555556, 0.9512195121951219, 0.9866666666666667, 0.9634146341463414, 0.96, 0.975, 0.9393939393939394, 0.9452054794520548, 1.0, 0.9459459459459459, 0.9866666666666667, 0.8507462686567164, 0.9322033898305084, 0.9875, 0.9493670886075949, 0.9295774647887324]\n",
      "[0.9662921348314607, 0.9753086419753086, 0.9873417721518988, 0.9642857142857143, 1.0, 0.9875, 0.9848484848484849, 0.9863013698630136, 1.0, 0.972972972972973, 1.0, 0.9365079365079365, 0.9661016949152542, 1.0, 0.9620253164556962, 0.9571428571428572]\n",
      "[0.9775280898876404, 0.9875, 0.9875, 0.9759036144578314, 1.0, 0.975609756097561, 0.9852941176470589, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9672131147540983, 0.95, 1.0, 0.9620253164556962, 0.9852941176470589]\n",
      "[0.9772727272727273, 0.9875, 0.9876543209876543, 0.9761904761904762, 1.0, 0.9878048780487805, 0.9852941176470589, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9672131147540983, 0.9666666666666667, 1.0, 0.95, 1.0]\n",
      "[0.9772727272727273, 0.9875, 0.9878048780487805, 0.9647058823529412, 1.0, 1.0, 0.9855072463768116, 0.9863013698630136, 1.0, 0.9863013698630136, 1.0, 0.9672131147540983, 0.9830508474576272, 1.0, 0.95, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9885057471264368, 0.975, 0.9024390243902439, 0.9634146341463414, 0.9473684210526315, 0.9512195121951219, 0.8857142857142857, 0.9583333333333334, 0.972972972972973, 0.9722222222222222, 0.9866666666666667, 0.9344262295081968, 0.9322033898305084, 0.9634146341463414, 0.9615384615384616, 0.9705882352941176]\n",
      "[0.9885057471264368, 0.9875, 0.9512195121951219, 0.9878048780487805, 0.9868421052631579, 0.9634146341463414, 0.9285714285714286, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9661016949152542, 0.9878048780487805, 0.9743589743589743, 0.9852941176470589]\n",
      "[1.0, 0.9875, 0.9634146341463414, 0.9878048780487805, 0.9868421052631579, 0.975609756097561, 0.9571428571428572, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9661016949152542, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[0.9885057471264368, 0.9875, 0.975609756097561, 1.0, 0.9736842105263158, 0.9878048780487805, 0.9571428571428572, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "[0.9885057471264368, 0.9875, 0.9878048780487805, 1.0, 0.9736842105263158, 0.975609756097561, 0.9714285714285714, 1.0, 0.9864864864864865, 1.0, 0.9866666666666667, 0.9672131147540983, 0.9830508474576272, 1.0, 0.9743589743589743, 0.9852941176470589]\n",
      "\n",
      "Accuracies: \n",
      "0.9616666666666667 0.98 0.9841666666666666 0.985 0.985 \n",
      "\n",
      "Precisions: \n",
      "[0.9777777777777777, 0.9761904761904762, 0.9390243902439024, 0.9523809523809523, 0.9315068493150684, 0.984375, 0.9318181818181818, 0.9841269841269841, 0.9714285714285714, 1.0, 0.948051948051948, 0.9875, 0.958904109589041, 0.9512195121951219, 0.9523809523809523, 0.9459459459459459]\n",
      "[0.989010989010989, 1.0, 0.9518072289156626, 0.9523809523809523, 0.9722222222222222, 0.984375, 0.9879518072289156, 0.9841269841269841, 0.9726027397260274, 1.0, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9512195121951219, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.975, 0.9523809523809523, 0.9722222222222222, 0.9846153846153847, 1.0, 0.9841269841269841, 0.9726027397260274, 1.0, 0.9866666666666667, 0.9875, 0.972972972972973, 0.9629629629629629, 1.0, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9753086419753086, 0.967741935483871, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.9726027397260274, 1.0, 0.9866666666666667, 0.9875, 0.972972972972973, 0.9629629629629629, 0.984375, 1.0]\n",
      "[0.989010989010989, 1.0, 0.9634146341463414, 0.967741935483871, 0.9859154929577465, 0.9846153846153847, 1.0, 0.9841269841269841, 0.9726027397260274, 1.0, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9629629629629629, 1.0, 1.0]\n",
      "\n",
      "Recalls: \n",
      "[0.9565217391304348, 0.9213483146067416, 0.9746835443037974, 0.9836065573770492, 0.9444444444444444, 0.984375, 0.9647058823529412, 0.9841269841269841, 0.9444444444444444, 0.9135802469135802, 0.9733333333333334, 0.9875, 0.958904109589041, 0.9873417721518988, 0.9523809523809523, 0.9722222222222222]\n",
      "[0.9782608695652174, 0.9550561797752809, 1.0, 0.9836065573770492, 0.9722222222222222, 0.984375, 0.9647058823529412, 0.9841269841269841, 0.9861111111111112, 0.9753086419753086, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9873417721518988, 1.0, 0.9722222222222222]\n",
      "[0.9782608695652174, 0.9550561797752809, 0.9873417721518988, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 0.9861111111111112]\n",
      "[0.9782608695652174, 0.9550561797752809, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9764705882352941, 0.9841269841269841, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9863013698630136, 0.9873417721518988, 1.0, 1.0]\n",
      "[0.9782608695652174, 0.9550561797752809, 1.0, 0.9836065573770492, 0.9722222222222222, 1.0, 0.9882352941176471, 0.9841269841269841, 0.9861111111111112, 0.9876543209876543, 0.9866666666666667, 0.9875, 0.9726027397260274, 0.9873417721518988, 1.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # Classify the test samples using k-nn with the standard approach and scaling\n",
    "    accuracies, precisions, recalls = knn(X_trains[i] ,  y_trains[i] , X_tests[i] , y_tests[i], k_array, False)\n",
    "    print1(accuracies, precisions, recalls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f68f7f6e936a2379902ade3d4fe5b5231ecd29e62f975957823cccc44bc63e47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
